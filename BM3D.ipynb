{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444d8c36-0c6a-46d1-802f-22b34207b0df",
   "metadata": {},
   "source": [
    "# BM3D\n",
    "\n",
    "Python implementation of [\"An Analysis and Implementation of the BM3D Image Denoising Method\" by Marc Lebrun](https://www.ipol.im/pub/art/2012/l-bm3d/?utm_source=doi)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d041d8d6-3423-438b-b92a-3ab11e8ced97",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211aa344-abcd-4790-80f1-fb84b0856c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io as skio\n",
    "import pywt\n",
    "import math\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05712f2-976b-4578-81ce-80543a3ea246",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ffdc80-cdfe-4025-b66c-fa8ff812366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st step\n",
    "kHard = 8  #patch size\n",
    "nHard = 39 #search window size --! era pra ser 39 mas nao entendi como centralizar P\n",
    "NHard = 16 #max number of similar patches kept \n",
    "pHard = 3\n",
    "\n",
    "sigma = 30\n",
    "tauHard = 5000 if sigma > 40 else 2500\n",
    "\n",
    "lambdaHard2d = 0 #hard thresholding for grouping --! ??? where\n",
    "lambdaHard3d = 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f167136-bf31-4819-8321-84ad1de63a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd step\n",
    "kWien = 8\n",
    "nWien = 39\n",
    "NWien = 32\n",
    "pWien = 3\n",
    "\n",
    "tauWien = 3500 if sigma > 40 else 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0922953d-31a7-4e56-a9eb-e5af9d3b4215",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e32b4-aed8-404f-855b-4ab68e6fdb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = skio.imread('./lena.tif') # original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54871e27-cfcd-4bf1-ac4f-fd0711a7663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = skio.imread('./muro.tif', as_gray=True) # original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd7d93-f29c-4876-ab6e-e4b893602904",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b73c2c5-0de4-4214-bc0a-21621611b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(im,br):\n",
    "    \"\"\" Cette fonction ajoute un bruit blanc gaussier d'ecart type br\n",
    "       a l'image im et renvoie le resultat\"\"\"\n",
    "    imt=np.float32(im.copy())\n",
    "    sh=imt.shape\n",
    "    bruit=br*np.random.randn(*sh)\n",
    "    imt=imt+bruit\n",
    "    return imt\n",
    "\n",
    "def noise2(im,br):\n",
    "    \"\"\" Cette fonction ajoute un bruit blanc gaussier d'ecart type br\n",
    "       a l'image im et renvoie le resultat\"\"\"\n",
    "    imt=np.float32(im.copy())\n",
    "    sh=imt.shape\n",
    "    bruit=np.random.normal(0, br, sh)\n",
    "    imt=imt+bruit\n",
    "    #imt = np.clip(imt, 0, 1)\n",
    "    return imt#np.float32(imt * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db188bf-a283-41fa-9276-2ad51dfdc7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize (image, vmin=0, vmax=255):\n",
    "    image = (image - image.min()) / (image.max() - image.min()) * vmax\n",
    "    image = np.clip(image, vmin, vmax).astype(np.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78941357-be24-4e17-b77f-6494fbe49a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = normalize(im)\n",
    "imbr = noise2(im, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec54e5-30c8-4f43-8441-89dcbb4c681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imbr, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b914620-be4e-4db2-b1cc-620585515cc4",
   "metadata": {},
   "source": [
    "## The First Denoising Step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d0666-cc16-489b-ace5-caed632c8c09",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb30dbfe-51ae-4aeb-80ef-4f8998eec213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y is the top-left corner of the reference patch\n",
    "# doesnt work well for even window_size --change\n",
    "def get_search_window(image, x, y, patch_size=kHard, window_size=nHard):\n",
    "    \"\"\" Given an image and the xy coordinates of the top-left corner of a reference patch\n",
    "        Finds the search window with the reference patch in the center\n",
    "        Returns the search window and the coordinates of its top-left pixel\n",
    "    \"\"\"\n",
    "        \n",
    "    window_top_left_x = x - (window_size//2 - patch_size//2)\n",
    "    window_top_left_y = y - (window_size//2 - patch_size//2)\n",
    "    \n",
    "    search_window = image[\n",
    "        window_top_left_x: window_top_left_x + window_size,\n",
    "        window_top_left_y: window_top_left_y + window_size \n",
    "    ]\n",
    "    return search_window, window_top_left_x, window_top_left_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edf731d-d868-4f95-9e42-72d2c29cdc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_thresholding(img, threshold):\n",
    "    \"\"\" Applies a hard thresholding operation to an array\n",
    "    \"\"\"\n",
    "    return (abs(img) > threshold) * img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7238a17-08ee-4dd0-a832-c262e4915402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_1st_step(x, y, image, sigma, patch_size, window_size, lambdaHard2d, tauHard, N=NHard):\n",
    "    # reference patch as array\n",
    "    ref_patch = image[x:x+patch_size, y:y+patch_size]\n",
    "    ref_patch_array = ref_patch.reshape(-1, patch_size**2)\n",
    "    \n",
    "    # vectorized patches from search window\n",
    "    search_window, x_win, y_win = get_search_window(image, x, y, patch_size, window_size)\n",
    "    window_patches = np.lib.stride_tricks.sliding_window_view(search_window, (patch_size, patch_size))\n",
    "    window_patches_array = window_patches.reshape(-1, patch_size**2)\n",
    "    \n",
    "    # hard thresholding\n",
    "    if sigma > 40:\n",
    "        ref_patch_array = hard_thresholding(ref_patch_array, lambdaHard2d * sigma)\n",
    "        window_patches_array = hard_thresholding(window_patches_array, lambdaHard2d * sigma)\n",
    "\n",
    "    # calculate vector differences to reference patch\n",
    "    diff_squared = (ref_patch_array - window_patches_array) **2\n",
    "    ssd_array = np.sum(diff_squared, axis=1)\n",
    "    dist_array = ssd_array / (kHard ** 2)\n",
    "    \n",
    "    # get N closest patches, N must be power of 2 and distance must be < tauHard\n",
    "    N = 2 ** (math.floor(math.log2(N)))\n",
    "    closer_indeces = dist_array.argsort()[:N]\n",
    "    closer_indeces = np.array([i for i in closer_indeces if dist_array[i] < tauHard]) #apply similarity threshold\n",
    "    \n",
    "    size = len(closer_indeces)\n",
    "    if not (size & (size-1) == 0):\n",
    "        new_size = 2 ** (math.floor(math.log2(size)))\n",
    "        closer_indeces = closer_indeces[:new_size]\n",
    "    \n",
    "    # get top left coord of each patch and build the 3d group\n",
    "    closer_coords = np.array([[x_win+(i//(window_size - patch_size + 1)), y_win+(i%(window_size - patch_size + 1))] for i in closer_indeces])\n",
    "    closer_patches = np.array([window_patches_array[i].reshape(patch_size, patch_size) for i in closer_indeces])\n",
    "\n",
    "    return closer_patches, closer_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ec97ee-7258-4db2-a62b-c89aed2f9011",
   "metadata": {},
   "source": [
    "After the grouping in 1st step, we get a list of tuples formed by: \n",
    "- a numpy array (N, 8, 8) where 1 <= N <= NHard (16), which represent a 3d group\n",
    "- the indeces (i, j) of the reference patch linked to that 3d group "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f949a19-e8c4-46b9-8191-0d97e34127d7",
   "metadata": {},
   "source": [
    "DÚVIDA: como lidar com patches que não formam grupos? acho que quando nenhum Q teve distancia abaixo da threshold. por enquanto vou só ignorar eles "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006e701-92ac-415c-9934-6f40465d5702",
   "metadata": {},
   "source": [
    "limitar N a uma potencia de 2 quando nao chega a 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88899578-fc66-41d2-b789-eeb2bb2d42b6",
   "metadata": {},
   "source": [
    "do we keep the reference patch in its 3d group?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cacf5b4-e2ee-4834-8f7d-0c7eb0f5e290",
   "metadata": {},
   "source": [
    "### Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903aa9f-b714-415d-bbe0-e533c3cb5f70",
   "metadata": {},
   "source": [
    "After the grouping in 1st step, we have a list of tuples formed by: \n",
    "- a numpy array (N, 8, 8) where 1 <= N <= NHard (16), which represent a 3d group\n",
    "- the indeces (i, j) of the reference patch linked to that 3d group "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd7146-a1da-4170-ac56-f8e9b959738e",
   "metadata": {},
   "source": [
    "In the Collaborative Filtering step, we will perform the following steps for each 3d group:\n",
    "1. apply a 3D isometric linear transform to the 3d block\n",
    "2. apply a hard thresholding operator with threshold $\\lambda ^{hard} _{3D} \\sigma$\n",
    "3. apply the inverse linear transform\n",
    "4. save in a buffer the estimate found for each pixel in each patch (this will later be used in the aggregation step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa6ddf4-be05-41d0-afe2-74f4c73b59fc",
   "metadata": {},
   "source": [
    "This means that the reference patch of size kHard x kHard (8x8) and top-left pixel in (18,489) should be estimated according to the 16 8x8 patches in the 3d group stored in a[1000][0]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904bc60b-121a-4f7b-9aa9-e9c8a5576052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walsh_hadamard_transform(x):\n",
    "    \"\"\"\n",
    "    Apply the Walsh-Hadamard transform on a 1D array.\n",
    "    \n",
    "    Parameters:\n",
    "    x (np.ndarray): 1D input array of length 2^n where n is a non-negative integer.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: The Walsh-Hadamard transformed array.\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    if n & (n - 1) != 0:\n",
    "        raise ValueError(\"Length of input array must be a power of 2\")\n",
    "\n",
    "    # Recursive base case\n",
    "    if n == 1:\n",
    "        return x\n",
    "    \n",
    "    # Split array into even and odd indexed parts\n",
    "    even = walsh_hadamard_transform(x[0::2])\n",
    "    odd = walsh_hadamard_transform(x[1::2])\n",
    "\n",
    "    return np.concatenate([even + odd, even - odd]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3598a5-7a19-4ab9-a5c5-5c93a02c2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Bior_matrices(N=8):\n",
    "    directBior15_matrix=np.zeros((N,N))\n",
    "    ss=N//2\n",
    "    ls=[]\n",
    "\n",
    "    while ss>0:\n",
    "        ls=ls+[ss]\n",
    "        ss=ss//2\n",
    "    print (ls)   \n",
    "    for k in range(N):\n",
    "        inp=np.zeros(N)\n",
    "        inp[k]=1\n",
    "        tmp=inp\n",
    "        out=[]\n",
    "        for s in ls:\n",
    "            #print (out,s)\n",
    "            (a,b)=pywt.dwt(tmp,'bior1.5',mode='periodic')\n",
    "            out=list(b[0:s])+out\n",
    "            tmp=a[:s]\n",
    "            #print ('sortie s=',s)\n",
    "        out=list(a[:s])+out\n",
    "        directBior15_matrix[k,:]=np.asarray(out)\n",
    "\n",
    "    invBior15_matrix=np.linalg.inv(directBior15_matrix)\n",
    "    return directBior15_matrix,invBior15_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8b7b7-3ce9-40ff-85b3-e7b16139ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bior(V,M,dim):\n",
    "    s=V.shape\n",
    "    l=[0,1,2]\n",
    "    l[dim]=0\n",
    "    l[0]=dim\n",
    "    smod=list(s)\n",
    "    smod[dim]=s[0]\n",
    "    smod[0]=s[dim]\n",
    "    return (M@V.transpose(l).reshape(((M.shape[0]),-1))).reshape(smod).transpose(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55f846-6464-4d74-b0a6-e152be1f6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_1d_transform(array, use_dct=False):\n",
    "    return walsh_hadamard_transform(array) / np.sqrt(len(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0c9ae-f935-4372-99c9-9ed6dfd41418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dct2d(block):\n",
    "    return dct(dct(block, axis=0, norm='ortho'), axis=1, norm='ortho')\n",
    "\n",
    "def idct2d(block):\n",
    "    return idct(idct(block, axis=1, norm='ortho'), axis=0, norm='ortho')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27836e2-e87c-47fd-9924-f6c6e4ecc551",
   "metadata": {},
   "outputs": [],
   "source": [
    "B8,IB8=get_Bior_matrices(N=8)\n",
    "def apply_2d_transform(v, use_dct=False):\n",
    "    if use_dct:\n",
    "        return [dct2d(block) for block in v]\n",
    "    else:\n",
    "        v1d=apply_bior(v,B8,-1)\n",
    "        v2d=apply_bior(v1d,B8,-2)\n",
    "        return v2d\n",
    "\n",
    "def reverse_2d_transform(v, use_dct=False):\n",
    "    if use_dct:\n",
    "        return [idct2d(block) for block in v]\n",
    "    else:\n",
    "        vappinv1d=apply_bior(v,IB8,-1)\n",
    "        vappinv2d=apply_bior(vappinv1d,IB8,-2)\n",
    "        return vappinv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9df5fd6-f0c6-4710-aa2a-60551c3a2c63",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf6a3a-54ad-438c-a5c1-9f76cbcce51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_aggregation_buffers(nu, delta, patches, coords, weights, X, Y):\n",
    "    weights = weights.reshape(-1,1,1)\n",
    "    \n",
    "    # Offset the grid for each patch position\n",
    "    X_ = X + coords[:, 0].reshape(-1, 1, 1)  \n",
    "    Y_ = Y + coords[:, 1].reshape(-1, 1, 1)  \n",
    "    \n",
    "    np.add.at(nu, (X_, Y_), patches * weights)\n",
    "    np.add.at(delta, (X_, Y_), weights) #######\n",
    "    \n",
    "    return nu, delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bfba50-5340-4523-8d85-fe2874ef4dbd",
   "metadata": {},
   "source": [
    "### 1st step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bbae4d-18bf-44b9-8b9f-0c53dcb2bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm3d_1st_step(image, sigma, kHard, nHard, lambdaHard2d, lambdaHard3d, tauHard, NHard):\n",
    "    height, width = image.shape\n",
    "\n",
    "    # pad image and iterate through original frame\n",
    "    window_size = nHard\n",
    "    offset = window_size // 2\n",
    "    padded_image = np.pad(image, offset, mode='reflect')\n",
    "\n",
    "    nu = np.zeros(padded_image.shape)\n",
    "    delta = np.zeros(padded_image.shape)\n",
    "\n",
    "    X, Y = np.meshgrid(np.arange(kHard), np.arange(kHard), indexing='ij')\n",
    "    \n",
    "    # iterate through patches in the image with a step\n",
    "    for x in range(offset, offset + height - kHard + 1, pHard):\n",
    "        for y in range(offset , offset + width - kHard + 1, pHard):\n",
    "\n",
    "            # GROUPING\n",
    "            group3d, coords = grouping_1st_step(x, y, padded_image, sigma, patch_size=kHard, window_size=nHard, lambdaHard2d=lambdaHard2d, tauHard=tauHard, N=NHard)\n",
    "            if len(coords) < 1:\n",
    "                continue\n",
    "\n",
    "            # COLLABORATIVE FILTERING\n",
    "            # 3d transform\n",
    "            transformed = np.array(apply_2d_transform(group3d, use_dct=False))\n",
    "            transformed = apply_1d_transform(transformed) #t1d\n",
    "\n",
    "            # thresholding\n",
    "            threshold = lambdaHard3d * sigma\n",
    "            thresholded = hard_thresholding(transformed, threshold)\n",
    "\n",
    "            # calculate weights\n",
    "            NPHard = np.count_nonzero(thresholded)\n",
    "            weight = 1/NPHard if NPHard >= 1 else 1\n",
    "            weight = np.array([weight])\n",
    "\n",
    "            # 3d reverse\n",
    "            thresholded = apply_1d_transform(thresholded) #t1d\n",
    "            \n",
    "            filtered = np.array(reverse_2d_transform(thresholded, use_dct=False))\n",
    "\n",
    "            # AGGREGATION \n",
    "            nu, delta = update_aggregation_buffers(nu, delta, filtered, coords, weight, X, Y)\n",
    "\n",
    "    ## BASIC ESTIMATE\n",
    "    basic = np.divide(nu[offset:offset+height, offset:offset+width], delta[offset:offset+height, offset:offset+width])\n",
    "\n",
    "    return basic, nu, delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8c450-3a92-49db-b302-26280d89d851",
   "metadata": {},
   "source": [
    "## The Second Denoising Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b79aa6-29a9-40a2-9195-b7bcb4ffa353",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_basic = bm3d_1st_step(imbr, sigma, kHard, nHard, lambdaHard2d, lambdaHard3d, tauHard, NHard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c55cc53-7cb9-4941-8086-9c7de0966133",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbeaa03-0ba7-4be3-b00c-4b82a9b6c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_2nd_step(x, y, image, basic, sigma, patch_size, window_size, lambdaHard2d, tauWien, NWien):\n",
    "    #group formed by the basic estimate\n",
    "    basic_patches, basic_coords = grouping_1st_step(x, y, basic, sigma, patch_size, window_size, lambdaHard2d, tauWien, NWien)\n",
    "\n",
    "    #group formed by the original image\n",
    "    original_patches = np.array([image[i:i+patch_size, j:j+patch_size] for i,j in basic_coords])\n",
    "\n",
    "    return original_patches, basic_patches, basic_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0168cc37-dee3-4515-a378-d3012fbcee79",
   "metadata": {},
   "source": [
    "### Collaborative Filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e5384-b9a7-4046-957a-a361511f7f73",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5852f75-aa10-47ac-a022-7e5e3ab904c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm3d_2nd_step(image, basic_estimate, sigma, kWien, nWien, lambdaHard2d, lambdaHard3d, tauWien, NWien):\n",
    "    height, width = image.shape\n",
    "\n",
    "    # pad image and iterate through original frame\n",
    "    window_size = nWien\n",
    "    offset = window_size // 2\n",
    "    padded_image = np.pad(image, offset, mode='reflect')\n",
    "    padded_basic = np.pad(basic_estimate, offset, mode='reflect')\n",
    "\n",
    "    nu = np.zeros(padded_image.shape)\n",
    "    delta = np.zeros(padded_image.shape)\n",
    "\n",
    "    X, Y = np.meshgrid(np.arange(kWien), np.arange(kWien), indexing='ij')\n",
    "    \n",
    "    # iterate through patches in the image with a step\n",
    "    for x in range(offset, offset + height - kWien + 1, pWien):\n",
    "        for y in range(offset , offset + width - kWien + 1, pWien):\n",
    "\n",
    "            # GROUPING\n",
    "            group3d_original, group3d_basic, coords = grouping_2nd_step(x, y, padded_image, padded_basic, sigma, patch_size=kWien, window_size=nWien, lambdaHard2d=lambdaHard2d, tauWien=tauWien, NWien=NWien)\n",
    "            if len(coords) < 1:\n",
    "                continue\n",
    "\n",
    "            # COLLABORATIVE FILTERING\n",
    "            # basic 3D transform\n",
    "            basic_transformed = np.array(apply_2d_transform(group3d_basic, use_dct=True))\n",
    "            basic_transformed = apply_1d_transform(basic_transformed) \n",
    "\n",
    "            # wiener coefficients over basic\n",
    "            module = np.absolute(basic_transformed) ** 2\n",
    "            wp = module / (module + sigma**2) \n",
    "\n",
    "            # original 3D transform\n",
    "            original_transformed = np.array(apply_2d_transform(group3d_original, use_dct=True))\n",
    "            original_transformed = apply_1d_transform(original_transformed) \n",
    "\n",
    "            # wiener filtering over original\n",
    "            original_filtered = wp * original_transformed\n",
    "\n",
    "            # 3D reverse\n",
    "            filtered = apply_1d_transform(original_filtered)\n",
    "            filtered = np.array(reverse_2d_transform(filtered, use_dct=True))\n",
    "\n",
    "            # calculate weights\n",
    "            weight = np.array([np.linalg.norm(wp) ** (-2)])\n",
    "\n",
    "            # AGGREGATION \n",
    "            nu, delta = update_aggregation_buffers(nu, delta, filtered, coords, weight, X, Y)\n",
    "\n",
    "    ## FINAL ESTIMATE\n",
    "    final = np.divide(nu[offset:offset+height, offset:offset+width], delta[offset:offset+height, offset:offset+width])\n",
    "\n",
    "    return final, nu, delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f318e-5e5a-4fa2-97c2-745cc8b36b71",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82138df-45b1-4c52-898d-2323df354251",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8212c9-a06b-44b3-bdf8-a33b3a1e992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imbr, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d045535-a8ee-4ced-90c7-810ab775d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "basic_estimate = bm3d_1st_step(imbr, sigma, kHard, nHard, lambdaHard2d, lambdaHard3d, tauHard, NHard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606e87ed-0a5a-41d8-a98b-3c676256fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 39//2\n",
    "height, width = im.shape\n",
    "nu = nu_basic[offset:offset+height, offset:offset+width]\n",
    "delta = delta_basic[offset:offset+height, offset:offset+width]\n",
    "np.count_nonzero(np.isnan(delta))\n",
    "delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a23c6dd-99b4-4451-89fe-29b6aa3f33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(basic_estimate, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651dc1ca-8f4b-4058-84cc-66c905cb4abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "final_estimate = bm3d_2nd_step(imbr, basic_estimate, sigma, kWien, nWien, lambdaHard2d, lambdaHard3d, tauWien, NWien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9760f4d-1efc-4082-b8d1-86bf5ff6c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(final_estimate, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb1c86a-9299-4f11-a050-aedaa316dd18",
   "metadata": {},
   "source": [
    "### PSNR: Peak Signal to Noise Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934464f-0037-4700-9477-f65a86abef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(reference_image, denoised_image):\n",
    "    \"\"\"\n",
    "    Compute the Root Mean Square Error (RMSE) between two images.\n",
    "    \n",
    "    Parameters:\n",
    "        reference_image (numpy.ndarray): The noiseless reference image (u_R).\n",
    "        denoised_image (numpy.ndarray): The denoised image (u_D).\n",
    "        \n",
    "    Returns:\n",
    "        float: The RMSE value.\n",
    "    \"\"\" \n",
    "    # Compute RMSE using vectorized operations\n",
    "    mse = np.mean((reference_image - denoised_image) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')  # PSNR is infinite if the images are identical\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6164e2-d974-44b4-8cb3-3640b3c3334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(reference_image, denoised_image):\n",
    "    \"\"\"\n",
    "    Compute the Root Mean Square Error (RMSE) between two images, ignoring NaN values.\n",
    "    \n",
    "    Parameters:\n",
    "        reference_image (numpy.ndarray): The noiseless reference image (u_R).\n",
    "        denoised_image (numpy.ndarray): The denoised image (u_D).\n",
    "        \n",
    "    Returns:\n",
    "        float: The RMSE value.\n",
    "    \"\"\"\n",
    "    # Create a mask to ignore NaN values in either image\n",
    "    valid_mask = ~np.isnan(reference_image) & ~np.isnan(denoised_image)\n",
    "    \n",
    "    # Apply the mask to select valid pixels only\n",
    "    valid_reference = reference_image[valid_mask]\n",
    "    valid_denoised = denoised_image[valid_mask]\n",
    "    \n",
    "    # Compute the Mean Squared Error (MSE) only over valid pixels\n",
    "    mse = np.mean((valid_reference - valid_denoised) ** 2)\n",
    "    \n",
    "    # If MSE is zero, return infinity for RMSE to reflect perfect similarity\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    # Compute RMSE\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d06060-ff7a-468b-8184-e569a7815bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psnr(reference_image, denoised_image):\n",
    "    \"\"\"\n",
    "    Compute the Peak Signal-to-Noise Ratio (PSNR) between two images.\n",
    "    \n",
    "    Parameters:\n",
    "        reference_image (numpy.ndarray): The noiseless reference image.\n",
    "        denoised_image (numpy.ndarray): The denoised image.\n",
    "        \n",
    "    Returns:\n",
    "        float: The PSNR value in decibels (dB).\n",
    "    \"\"\"\n",
    "    # Ensure the two images have the same shape\n",
    "    assert reference_image.shape == denoised_image.shape, \"Images must have the same dimensions\"\n",
    "    \n",
    "    # Compute RMSE\n",
    "    rmse = compute_rmse(reference_image, denoised_image)\n",
    "    \n",
    "    # Compute PSNR\n",
    "    max_pixel_value = 255.0  # Assuming 8-bit images with pixel values in [0, 255]\n",
    "    psnr = 20 * np.log10(max_pixel_value / rmse)\n",
    "    \n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a37a8be-adea-4958-972f-5b13289b31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_psnr(im, basic_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74dd555-e20e-42a5-818f-29f04836f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_psnr(im, final_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81db9f68-9079-42c6-9bc1-aecabcab2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(np.isnan(basic_estimate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f1095f-118d-47d5-b711-6cfdad4d68bf",
   "metadata": {},
   "source": [
    "subplot: original \\ noisy (sigma) \\ 1st step (psnr) \\ 2nd step (psnr) \\ tempo de execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e392931-eb46-4ae6-83b1-2e09e50e65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_images_with_note_and_subtitles(images, titles, subtitles, note, figsize=(10, 8)):\n",
    "    \"\"\"\n",
    "    Display 4 images in a 2x2 grid with titles, and subtitles for the last two images.\n",
    "    Add a note in the bottom-right corner.\n",
    "    \n",
    "    Parameters:\n",
    "        images (list of numpy.ndarray): List of 4 images to display.\n",
    "        titles (list of str): List of 4 titles corresponding to the images.\n",
    "        subtitles (list of str): List of 2 subtitles for the last two images (or empty strings if not needed).\n",
    "        note (str): The note to display in the bottom-right corner (e.g., execution time).\n",
    "        figsize (tuple): Size of the entire figure.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Check if input is valid\n",
    "    if len(images) != 4 or len(titles) != 4 or len(subtitles) != 2:\n",
    "        raise ValueError(\"You must provide exactly 4 images, 4 titles, and 2 subtitles.\")\n",
    "    \n",
    "    # Create the figure and axes for the subplot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "    axes = axes.flatten()  # Flatten the 2x2 grid into a 1D array for easier iteration\n",
    "    \n",
    "    # Plot each image with its corresponding title and subtitles (if applicable)\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(images[i], cmap='gray', vmin=0, vmax=255)  # Assuming grayscale images\n",
    "        ax.set_title(titles[i], fontsize=12, pad=10)  # Title above the image\n",
    "        ax.axis('off')  # Hide axes for a cleaner look\n",
    "        \n",
    "        # Add subtitle below the last two images\n",
    "        if i >= 2:  # Indices 2 and 3 correspond to the last two images\n",
    "            ax.text(\n",
    "                0.5, -0.05, subtitles[i - 2],  # Subtitle positioned closer to the image\n",
    "                ha='center', va='center', transform=ax.transAxes, fontsize=10, color='black'\n",
    "            )\n",
    "    \n",
    "    # Adjust layout to make space for the note at the bottom\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2)  # Add space at the bottom for the note\n",
    "    \n",
    "    # Add a small note in the bottom-right corner\n",
    "    fig.text(0.95, 0.03, note, ha='right', fontsize=10, color='blue')  # Bottom-right corner note\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create example grayscale images (random noise for demonstration purposes)\n",
    "    images = [np.random.randint(0, 256, (100, 100), dtype=np.uint8) for _ in range(4)]\n",
    "    titles = [\"Image 1\", \"Image 2\", \"Image 3\", \"Image 4\"]\n",
    "    subtitles = [\"Subtitle for Image 3\", \"Subtitle for Image 4\"]\n",
    "    note = \"Execution Time: 1.23 seconds\"\n",
    "    \n",
    "    # Call the function to plot images with titles, subtitles, and the note\n",
    "    plot_images_with_note_and_subtitles(images, titles, subtitles, note)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
